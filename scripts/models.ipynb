{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Selection du modèle\n",
    "\n",
    " Dans notre projet, nous traitons un problème de classification binaire où nous devons classer le compte Instagram d'un utilisateur donné comme réel ou faux. Par conséquent, nous nous limiterons à expliquer les différents algorithmes de classification binaire possibles et nous comprendrons pourquoi ils sont considérés comme adaptés à notre projet dans les sections ultérieures."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps nous avons importer les librairies nécessaires pour l'implémentation des différents modèles.\n",
    "Ensuite, nous avons importer et diviser le jeu de données en données d'entrainement et données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "\n",
    "# file to use differents ML models and compare them\n",
    "\n",
    "# load  the data \n",
    "#users_json = json.load(open('../data/accountData_clean.json'))\n",
    "\n",
    "data = pd.read_json('../data/accountData_clean.json')\n",
    "    \n",
    "y = data.isFake\n",
    "X = data.drop(['isFake'], axis=1)\n",
    "\n",
    "#split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=242)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM) : \n",
    "le SVM est un classificateur à marge maximale. Il s'appuie sur les vecteurs de support pour définir une limite de décision sur un ensemble de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9937238493723849\n",
      "[[387   1]\n",
      " [  2  88]]\n"
     ]
    }
   ],
   "source": [
    "def svm_Training ():\n",
    "       \n",
    "    #Import svm model \n",
    "    from sklearn import svm\n",
    "\n",
    "    #create a svm classifier\n",
    "    clf = svm.SVC(kernel='linear', C=100.0) # Linear Kernel\n",
    "\n",
    "    #train the model\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    #predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    #Import scikit-learn metrics module for accuracy calculation\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    # Model confusion   \n",
    "    from sklearn.metrics import confusion_matrix        \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Model Precision\n",
    "    #from sklearn.metrics import precision_score\n",
    "    #print(\"Precision:\",precision_score(y_test, y_pred))\n",
    "\n",
    "svm_Training()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network :\n",
    "Les réseaux neuronaux sont des simulations artificielles du réseau neuronal biologique du cerveau humain dans des ordinateurs. Ils utilisent des perceptrons, un équivalent artificiel des neurones biologiques. Les neurones sont connectés les uns aux autres de manière hiérarchique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 80        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "val_accuracycl: 97.03%\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9707\n",
      "\n",
      "accuracy: 97.07%\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing for NN\n",
    "\n",
    "X_train = data[pd.notnull(data['isFake'])].drop(['isFake'],axis=1)\n",
    "y_train= data[pd.notnull(data['isFake'])]['isFake']\n",
    "X_test = data[pd.isnull(data['isFake'])].drop(['isFake'],axis=1)\n",
    "\n",
    "def NN_Training(lyrs=[8], act='linear', opt='Adam', dr=0.0):\n",
    "\n",
    "\n",
    "    #data preprocessing\n",
    "   \n",
    "\n",
    "      # set random seed for reproducibility\n",
    "    seed(42)\n",
    "    tensorflow.random.set_seed(42)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # create first hidden layer\n",
    "    model.add(Dense(lyrs[0], input_dim=X_train.shape[1], activation=act))\n",
    "    \n",
    "    # create additional hidden layers\n",
    "    for i in range(1,len(lyrs)):\n",
    "        model.add(Dense(lyrs[i], activation=act))\n",
    "    \n",
    "    # add dropout, default is none\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    # create output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # output layer\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    # fit the model\n",
    "    training = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    #print(training.history)\n",
    "    val_acc = np.mean(training.history['val_accuracy'])\n",
    "    print(\"\\n%s: %.2f%%\" % ('val_accuracycl', val_acc*100))\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_train, y_train)\n",
    "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    # make  predictions on test set\n",
    "    #test['isFake'] = model.predict(X_test)\n",
    "    #test['isFake'] = test['isFake'].apply(lambda x: round(x,0)).a\n",
    "    #test['isFake'] = test['isFake'].astype(int)\n",
    "\n",
    "    #solution(test[['id','isFake']])\n",
    "\n",
    "NN_Training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
